{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgDcG7n80hjS"
      },
      "source": [
        "### Base Model : Transfer Learning based on Inception V3\n",
        "> Inception V3 모델의 객체 생성, ImageNet dataset으로 pre-trained된 weight 사용\n",
        "\n",
        "\n",
        "* include_top = False : 분류기는 pre-train에서 제외\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOocO_mU-TfI",
        "outputId": "290cdb08-71d2-4af0-97b8-b4364c06947c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Base Model\n",
        "# Inception V3 불러오기 - ImageNet 데이터셋으로 pre-train된 가중치 사용\n",
        "base_model = applications.InceptionV3(weights='imagenet', include_top=False,input_shape=(ROWS, COLS,3)) # include_top=False : 분류기는 pre-train에서 제외\n",
        "\n",
        "# 처음부터 150번째 layer까지는 학습이 되지 않도록 설정\n",
        "for i in base_model.layers[0:150]:\n",
        "    i.trainable = False\n",
        "\n",
        "# 150번째 이후 layer들은 학습이 가능하도록 설정\n",
        "for i in base_model.layers[150::]:\n",
        "    i.trainable = True\n",
        "\n",
        "add_model = Sequential()\n",
        "add_model.add(base_model) # Feature Extraction 부분 추가\n",
        "add_model.add(GlobalAveragePooling2D())\n",
        "add_model.add(Dropout(0.5))\n",
        "add_model.add(Dense(12, activation='softmax'))\n",
        "\n",
        "model = add_model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.Adam(learning_rate=1e-3),\n",
        "              metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nreqz_phxDYo",
        "outputId": "2b5595ed-13bc-4804-cb96-892f1fed16f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "311\n"
          ]
        }
      ],
      "source": [
        "print(len(base_model.layers))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nu_5hEnY-Tbk",
        "outputId": "6ad136f3-5162-4ee7-9fd9-2ddfa5fe66c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 1.2473290598290598,\n",
              " 1: 1.8227946916471507,\n",
              " 2: 0.8040633608815427,\n",
              " 3: 0.2782743415564295,\n",
              " 4: 7.783333333333333,\n",
              " 5: 0.7846102150537635,\n",
              " 6: 1.018760907504363,\n",
              " 7: 11.974358974358974,\n",
              " 8: 0.7260572139303483,\n",
              " 9: 1.0676726108824874,\n",
              " 10: 4.605522682445759,\n",
              " 11: 1.229594523433386}"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 훈련 데이터의 각 {class, wieght}\n",
        "train_classes = train_generator.classes\n",
        "class_weights = compute_class_weight(\n",
        "                                        class_weight = \"balanced\",\n",
        "                                        classes = np.unique(train_classes),\n",
        "                                        y = train_classes\n",
        "                                    )\n",
        "class_weights = dict(zip(np.unique(train_classes), class_weights))\n",
        "class_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_QCYnL31qZP"
      },
      "source": [
        ">  Training\n",
        "* checkpoint : 훈련 중, 검증 정확도가 최대가 되는 모델의 가중치 저장한다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0eAX4Kyh_m9I"
      },
      "outputs": [],
      "source": [
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5)\n",
        "\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath='base_model_inception', # 저장할 파일의 경로\n",
        "    save_weights_only=False, # 전체 모델 저장\n",
        "    monitor='val_accuracy',\n",
        "    mode='max', # 검증 정확도의 최대값을 찾는다.\n",
        "    save_best_only=True, # 최적의 가중치만 저장\n",
        "    verbose =1) # 진행 상황 출력\n",
        "\n",
        "history = model.fit(train_generator, validation_data=valid_generator, callbacks=[early_stopping, checkpoint],\n",
        "                    class_weight=class_weights,\n",
        "                    epochs=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYM7ZRVG3XIQ"
      },
      "outputs": [],
      "source": [
        "# 약 4시간 걸림\n",
        "# checkpoint 경로 다시 살펴보기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Ic3YStWJny0"
      },
      "outputs": [],
      "source": [
        "# 재학습 시, 이전에 저장된 모델 가중치를 불러온다.\n",
        "model.load_weights('base_model_inception')\n",
        "\n",
        "# 이어서 모델 학습\n",
        "model.fit(train_generator, validation_data=valid_generator, callbacks=[early_stopping, checkpoint],\n",
        "                    class_weight=class_weights,\n",
        "                    epochs=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZJU_H2071Wh",
        "outputId": "c5b31efc-2c02-4aec-b09b-d16adbdbd26b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "32/37 [========================>.....] - ETA: 2s - loss: 0.9744 - accuracy: 0.8130"
          ]
        }
      ],
      "source": [
        "model.evaluate(valid_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YESgQI28JTh2"
      },
      "outputs": [],
      "source": [
        "model.save('base_model.inception')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeFCuaumGIDX"
      },
      "source": [
        "class_weight를 고려한 결과로는, 손실은 0.2정도 줄었지만, accuracy도 0.1정도 줄었다.\n",
        "> * 클래스 가중치를 통해 불균형한 클래스 분포를 고려하였기 때문에 손실이 줄어들었다.\n",
        "* 반면, 정확도의 감소는 클래스 가중치를 사용하면서 더 많은 잘못 분류된 샘플이 발생했다.\n",
        "* 이러한 결과는, 클래스 가중치를 사용하는 것이 모델의 손실을 줄이는 데 도움을 줄 수 있지만, 정확도와의 trade-off 가 발생한 것을 나타낸다."
      ]
    }
  ]
}