{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7PWxCwpqGk1"
      },
      "source": [
        "### Big image classification test\n",
        "\n",
        "class가 자전거인 경우에는 자전거가 포함된 이미지를 1/3 비율로 가져오고, 랜덤하게 선택한 다른 클래스의 이미지를 2/3 비율로 가져와서 테스트를 진행해보았습니다. 이 과정에서 자전거가 아닌 이미지는 클래스 0으로 예측하고, 자전거가 포함된 이미지는 클래스1로 예측하게 됩니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 9388 images belonging to 12 classes.\n",
            "Found 2342 images belonging to 12 classes.\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "from tensorflow import keras\n",
        "from keras.models import load_model\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "from joblib import load\n",
        "import tensorflow as tf\n",
        "from vit_keras import vit, layers\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# 모델 예측 성능 체크 완료!!!!!! 잘 예측됨 !!!!!!!!\n",
        "# 우선 먼저, 이미지 예측 되나 확인부터 해보자. 하나의 이미지 가져와서.\n",
        "vit_model = keras.models.load_model('../vit_model.h5')\n",
        "\n",
        "# hyperparameter\n",
        "BATCH_SIZE = 32\n",
        "ROWS = 224\n",
        "COLS = 224\n",
        "input_shape = (ROWS, COLS, 3) # 이미지의 높이, 너비가 각각 224 pixel이고, 채널 수가 3인 RGB이미지임.\n",
        "\n",
        "image_path = '../Data/Big Image Data'\n",
        "\n",
        "# 이미지 데이터 전처리\n",
        "train_data = ImageDataGenerator(rescale=1/255.0, # 이미지 픽셀 값 0~1 normalization\n",
        "                                zoom_range=0.05, # 이미지 확대/ 축소 범위 -> 다양한 시각적 변화 도입\n",
        "                                horizontal_flip=True, # 수평으로 뒤집기 -> 이미지의 좌우 대칭성 고려\n",
        "                                validation_split=0.2)\n",
        "\n",
        "\n",
        "# 훈련 데이터 생성기\n",
        "train_generator = train_data.flow_from_directory(directory=image_path,\n",
        "                                                 target_size=(224,224),\n",
        "                                                 color_mode='rgb',\n",
        "                                                 batch_size=BATCH_SIZE,\n",
        "                                                 class_mode='categorical',\n",
        "                                                 subset='training',\n",
        "                                                 shuffle=True,\n",
        "                                                 seed=42\n",
        "                                                 )\n",
        "\n",
        "# 검증 데이터 생성기\n",
        "valid_generator = train_data.flow_from_directory(directory=image_path,\n",
        "                                                 target_size=(224,224),\n",
        "                                                 color_mode='rgb',\n",
        "                                                 batch_size=BATCH_SIZE,\n",
        "                                                 class_mode='categorical',\n",
        "                                                 subset='validation',\n",
        "                                                 shuffle=True,\n",
        "                                                 seed=42\n",
        "                                                 )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Zv8hWcqSFmsr"
      },
      "outputs": [],
      "source": [
        "def create_test_generator(image_path, class_name, exclude_classes):\n",
        "  # 각 라벨별 테스트 생성기 함수\n",
        "  # 라벨 포함 생성기\n",
        "  test_class_generator = train_data.flow_from_directory(\n",
        "    directory=image_path,\n",
        "    target_size=(224, 224),\n",
        "    color_mode='rgb',\n",
        "    batch_size=10,\n",
        "    classes=[class_name],\n",
        "    class_mode='categorical',\n",
        "    shuffle=True\n",
        "  )\n",
        "\n",
        "  # 라벨 제외 생성기\n",
        "  test_non_class_generator = train_data.flow_from_directory(\n",
        "      directory=image_path,\n",
        "      target_size=(224, 224),\n",
        "      color_mode='rgb',\n",
        "      batch_size=10,\n",
        "      classes=[class_name for class_name in train_generator.class_indices.keys() if class_name not in exclude_classes],\n",
        "      class_mode='categorical',\n",
        "      shuffle=True\n",
        "  )\n",
        "\n",
        "  return test_class_generator, test_non_class_generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTNJv3ocGWS1",
        "outputId": "70a27813-d1ae-48fb-81f2-2b13f86f20a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 780 images belonging to 1 classes.\n",
            "Found 10950 images belonging to 11 classes.\n",
            "Found 533 images belonging to 1 classes.\n",
            "Found 11197 images belonging to 11 classes.\n",
            "Found 1209 images belonging to 1 classes.\n",
            "Found 10521 images belonging to 11 classes.\n",
            "Found 3558 images belonging to 1 classes.\n",
            "Found 8172 images belonging to 11 classes.\n",
            "Found 124 images belonging to 1 classes.\n",
            "Found 11606 images belonging to 11 classes.\n",
            "Found 1240 images belonging to 1 classes.\n",
            "Found 10490 images belonging to 11 classes.\n",
            "Found 952 images belonging to 1 classes.\n",
            "Found 10778 images belonging to 11 classes.\n",
            "Found 81 images belonging to 1 classes.\n",
            "Found 11649 images belonging to 11 classes.\n",
            "Found 911 images belonging to 1 classes.\n",
            "Found 10819 images belonging to 11 classes.\n",
            "Found 211 images belonging to 1 classes.\n",
            "Found 11519 images belonging to 11 classes.\n",
            "Found 791 images belonging to 1 classes.\n",
            "Found 10939 images belonging to 11 classes.\n"
          ]
        }
      ],
      "source": [
        "test_bicycle_generator, test_non_bicycle_generator = create_test_generator(image_path, 'Bicycle', 'Bicycle')\n",
        "test_bridge_generator, test_non_bridge_generator = create_test_generator(image_path, 'Bridge', 'Bridge')\n",
        "test_bus_generator, test_non_bus_generator = create_test_generator(image_path, 'Bus', 'Bus')\n",
        "test_car_generator, test_non_car_generator = create_test_generator(image_path, 'Car', 'Car')\n",
        "test_chimney_generator, test_non_chimney_generator = create_test_generator(image_path, 'Chimney', 'Chimney')\n",
        "test_crosswalk_generator, test_non_crosswalk_generator = create_test_generator(image_path, 'Crosswalk', 'Crosswalk')\n",
        "test_hydrant_generator, test_non_hydrant_generator = create_test_generator(image_path, 'Hydrant', 'Hydrant')\n",
        "test_motorcycle_generator, test_non_motorcycle_generator = create_test_generator(image_path, 'Motorcycle', 'Motorcycle')\n",
        "test_palm_generator, test_non_palm_generator = create_test_generator(image_path, 'Palm', 'Palm')\n",
        "test_stair_generator, test_non_stair_generator = create_test_generator(image_path, 'Stair', 'Stair')\n",
        "test_traffic_light_generator, test_non_traffic_light_generator = create_test_generator(image_path, 'Traffic Light', 'Traffic Light')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UPNi8mH9Aay0"
      },
      "outputs": [],
      "source": [
        "def load_images_from_generator(generator, num_images):\n",
        "    images = []\n",
        "    labels = []\n",
        "    num_loaded = 0\n",
        "\n",
        "    while num_loaded < num_images:\n",
        "        batch_images, batch_labels = next(generator)\n",
        "        images.append(batch_images)\n",
        "        labels.append(batch_labels)\n",
        "        num_loaded += len(batch_images)\n",
        "\n",
        "    images = np.concatenate(images)[:num_images]\n",
        "    labels = np.concatenate(labels)[:num_images]\n",
        "\n",
        "    return images, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2ulXhhjXdfAu"
      },
      "outputs": [],
      "source": [
        "bicycle_images, bicycle_labels = load_images_from_generator(test_bicycle_generator, 200)\n",
        "non_bicycle_images, non_bicycle_labels = load_images_from_generator(test_non_bicycle_generator, 400)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hdi6nR2KeRYK"
      },
      "outputs": [],
      "source": [
        "bridge_images, bridge_labels = load_images_from_generator(test_bridge_generator, 200)\n",
        "non_bridge_images, non_bridge_labels = load_images_from_generator(test_non_bridge_generator, 400)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jwpRa30BeRJK"
      },
      "outputs": [],
      "source": [
        "bus_images, bus_labels = load_images_from_generator(test_bus_generator, 200)\n",
        "non_bus_images, non_bus_labels = load_images_from_generator(test_non_bus_generator, 400)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "bEEubnyTh9XB"
      },
      "outputs": [],
      "source": [
        "car_images, car_labels = load_images_from_generator(test_car_generator, 200)\n",
        "non_car_images, non_car_labels = load_images_from_generator(test_non_car_generator, 400)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "t_WQGvPhh9Tk"
      },
      "outputs": [],
      "source": [
        "chimney_images, chimney_labels = load_images_from_generator(test_chimney_generator, 200)\n",
        "non_chimney_images, non_chimney_labels = load_images_from_generator(test_non_chimney_generator, 400)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "fvFTLE8-h9Qn"
      },
      "outputs": [],
      "source": [
        "cro_images, cro_labels = load_images_from_generator(test_crosswalk_generator, 200)\n",
        "non_cro_images, non_cro_labels = load_images_from_generator(test_non_crosswalk_generator, 400)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "E_sFNvZY_4SR"
      },
      "outputs": [],
      "source": [
        "hydrant_images, hydrant_labels = load_images_from_generator(test_hydrant_generator, 200)\n",
        "non_hydrant_images, non_hydrant_labels = load_images_from_generator(test_non_hydrant_generator, 400)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "r1_KREvXAIlt"
      },
      "outputs": [],
      "source": [
        "moto_images, moto_labels = load_images_from_generator(test_motorcycle_generator, 81)\n",
        "non_moto_images, non_moto_labels = load_images_from_generator(test_non_motorcycle_generator, 160)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "4aTy2AUUAIff"
      },
      "outputs": [],
      "source": [
        "palm_images, palm_labels = load_images_from_generator(test_palm_generator, 200)\n",
        "non_palm_images, non_palm_labels = load_images_from_generator(test_non_palm_generator, 400)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "MyiuKUIMAn9L"
      },
      "outputs": [],
      "source": [
        "stair_images, stair_labels = load_images_from_generator(test_stair_generator, 200)\n",
        "non_stair_images, non_stair_labels = load_images_from_generator(test_non_stair_generator, 400)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "D7NBJzpwAn5z"
      },
      "outputs": [],
      "source": [
        "tf_images, tf_labels = load_images_from_generator(test_traffic_light_generator, 200)\n",
        "non_tf_images, non_tf_labels = load_images_from_generator(test_non_traffic_light_generator, 400)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "lXnZy4uFcyvl"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def evaluate_class_performance(vit_model, target_class, target_images, non_target_images):\n",
        "    class_indices = train_generator.class_indices\n",
        "\n",
        "    # Index of the target class\n",
        "    target_index = class_indices[target_class]\n",
        "\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "\n",
        "    # For target images\n",
        "    target_preds = vit_model.predict(target_images)\n",
        "\n",
        "    for pred in target_preds:\n",
        "        predicted_class = np.argmax(pred)\n",
        "        if predicted_class == target_index:\n",
        "            predictions.append(1)  # target class\n",
        "        else:\n",
        "            predictions.append(0)  # non-target class\n",
        "        true_labels.append(1)  # Always 1 for target class\n",
        "\n",
        "    # For non-target images\n",
        "    non_target_preds = vit_model.predict(non_target_images)\n",
        "\n",
        "    for pred in non_target_preds:\n",
        "        predicted_class = np.argmax(pred)\n",
        "        if predicted_class == target_index:\n",
        "            predictions.append(1)  # target class\n",
        "        else:\n",
        "            predictions.append(0)  # non-target class\n",
        "        true_labels.append(0)  # Always 0 for non-target class\n",
        "\n",
        "    return classification_report(true_labels, predictions)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9MVuOEokj30"
      },
      "source": [
        "0 : 특정 클래스 제외  \n",
        "1 : 해당 클래스"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "QR28gxXWkwWd"
      },
      "outputs": [],
      "source": [
        "classes = [\n",
        "    ('Bicycle', bicycle_images, non_bicycle_images),\n",
        "    ('Bridge', bridge_images, non_bridge_images),\n",
        "    ('Bus', bus_images, non_bus_images),\n",
        "    ('Car', car_images, non_car_images),\n",
        "    ('Chimney', chimney_images, non_chimney_images),\n",
        "    ('Crosswalk', cro_images, non_cro_images),\n",
        "    ('Hydrant', hydrant_images, non_hydrant_images),\n",
        "    ('Motorcycle', moto_images, non_moto_images),\n",
        "    ('Palm', palm_images, non_palm_images),\n",
        "    ('Stair', stair_images, non_stair_images),\n",
        "    ('Traffic Light', tf_images, non_tf_images)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilyI4__MktPY",
        "outputId": "b9a0f355-46ab-4085-a883-85aaf105b88e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7/7 [==============================] - 39s 4s/step\n",
            "13/13 [==============================] - 58s 4s/step\n",
            "Performance for Bicycle:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       400\n",
            "           1       1.00      0.95      0.98       200\n",
            "\n",
            "    accuracy                           0.98       600\n",
            "   macro avg       0.99      0.98      0.98       600\n",
            "weighted avg       0.99      0.98      0.98       600\n",
            "\n",
            "============================================\n",
            "7/7 [==============================] - 24s 3s/step\n",
            "13/13 [==============================] - 52s 4s/step\n",
            "Performance for Bridge:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98       400\n",
            "           1       0.99      0.93      0.96       200\n",
            "\n",
            "    accuracy                           0.97       600\n",
            "   macro avg       0.98      0.96      0.97       600\n",
            "weighted avg       0.97      0.97      0.97       600\n",
            "\n",
            "============================================\n",
            "7/7 [==============================] - 25s 4s/step\n",
            "13/13 [==============================] - 50s 4s/step\n",
            "Performance for Bus:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       400\n",
            "           1       0.99      0.98      0.98       200\n",
            "\n",
            "    accuracy                           0.99       600\n",
            "   macro avg       0.99      0.99      0.99       600\n",
            "weighted avg       0.99      0.99      0.99       600\n",
            "\n",
            "============================================\n",
            "7/7 [==============================] - 25s 3s/step\n",
            "13/13 [==============================] - 49s 4s/step\n",
            "Performance for Car:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.94      0.97       400\n",
            "           1       0.89      0.98      0.94       200\n",
            "\n",
            "    accuracy                           0.95       600\n",
            "   macro avg       0.94      0.96      0.95       600\n",
            "weighted avg       0.96      0.95      0.96       600\n",
            "\n",
            "============================================\n",
            "7/7 [==============================] - 25s 4s/step\n",
            "13/13 [==============================] - 51s 4s/step\n",
            "Performance for Chimney:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98       400\n",
            "           1       1.00      0.92      0.96       200\n",
            "\n",
            "    accuracy                           0.97       600\n",
            "   macro avg       0.98      0.96      0.97       600\n",
            "weighted avg       0.97      0.97      0.97       600\n",
            "\n",
            "============================================\n",
            "7/7 [==============================] - 27s 4s/step\n",
            "13/13 [==============================] - 51s 4s/step\n",
            "Performance for Crosswalk:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97       400\n",
            "           1       1.00      0.87      0.93       200\n",
            "\n",
            "    accuracy                           0.96       600\n",
            "   macro avg       0.97      0.94      0.95       600\n",
            "weighted avg       0.96      0.96      0.96       600\n",
            "\n",
            "============================================\n",
            "7/7 [==============================] - 26s 4s/step\n",
            "13/13 [==============================] - 49s 4s/step\n",
            "Performance for Hydrant:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       400\n",
            "           1       1.00      1.00      1.00       200\n",
            "\n",
            "    accuracy                           1.00       600\n",
            "   macro avg       1.00      1.00      1.00       600\n",
            "weighted avg       1.00      1.00      1.00       600\n",
            "\n",
            "============================================\n",
            "3/3 [==============================] - 9s 3s/step\n",
            "5/5 [==============================] - 17s 3s/step\n",
            "Performance for Motorcycle:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98       160\n",
            "           1       1.00      0.94      0.97        81\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.98      0.97      0.98       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "============================================\n",
            "7/7 [==============================] - 21s 3s/step\n",
            "13/13 [==============================] - 38s 3s/step\n",
            "Performance for Palm:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.99       400\n",
            "           1       1.00      0.94      0.97       200\n",
            "\n",
            "    accuracy                           0.98       600\n",
            "   macro avg       0.99      0.97      0.98       600\n",
            "weighted avg       0.98      0.98      0.98       600\n",
            "\n",
            "============================================\n",
            "7/7 [==============================] - 19s 3s/step\n",
            "13/13 [==============================] - 37s 3s/step\n",
            "Performance for Stair:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98       400\n",
            "           1       1.00      0.92      0.96       200\n",
            "\n",
            "    accuracy                           0.97       600\n",
            "   macro avg       0.98      0.96      0.97       600\n",
            "weighted avg       0.97      0.97      0.97       600\n",
            "\n",
            "============================================\n",
            "7/7 [==============================] - 20s 3s/step\n",
            "13/13 [==============================] - 38s 3s/step\n",
            "Performance for Traffic light:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      1.00      0.96       400\n",
            "           1       1.00      0.82      0.90       200\n",
            "\n",
            "    accuracy                           0.94       600\n",
            "   macro avg       0.96      0.91      0.93       600\n",
            "weighted avg       0.95      0.94      0.94       600\n",
            "\n",
            "============================================\n"
          ]
        }
      ],
      "source": [
        "def evaluate_all_classes(vit_model, classes):\n",
        "    for class_name, target_images, non_target_images in classes:\n",
        "        report = evaluate_class_performance(vit_model, class_name, target_images, non_target_images)\n",
        "        print(f\"Performance for {class_name.capitalize()}:\")\n",
        "        print(report)\n",
        "        print(\"============================================\")\n",
        "\n",
        "evaluate_all_classes(vit_model, classes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpmzkogxJQGk"
      },
      "source": [
        "| Class          | Accuracy | F1-score (Target Class) | F1-score (Non-Target Class) | Count |\n",
        "|----------------|----------|-------------------------|-----------------------------|-------|\n",
        "| Bicycle        |   0.99   |      0.98               |      0.99                   | 600   |\n",
        "| Bridge         |   0.97   |      0.96               |      0.98                   | 600   |\n",
        "| Bus            |   0.98   |      0.97               |      0.99                   | 600   |\n",
        "| Car            |   0.95   |      0.93               |      0.96                   | 600   |\n",
        "| Chimney        |   0.97   |      0.96               |      0.98                   | 600   |\n",
        "| Crosswalk      |   0.95   |      0.92               |      0.97                   | 600   |\n",
        "| Hydrant        |   1.00   |      1.00               |      1.00                   | 600   |\n",
        "| Motorcycle     |   0.99   |      0.98               |      0.99                   | 241   |\n",
        "| Palm           |   0.97   |      0.95               |      0.98                   | 600   |\n",
        "| Stair          |   0.97   |      0.96               |      0.98                   | 600   |\n",
        "| Traffic Light  |   0.95   |      0.93               |      0.97                   | 600   |\n",
        "| **Average Total**      |   **0.97** | **0.96**  | **0.98** | 6051 |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
